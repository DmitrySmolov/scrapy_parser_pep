
# Проект парсинга scrapy_parser_pep

scrapy_parser_pep это асинхронный парсер, удобно компилирующий информацию по статьям PEP (Python Enhancement Proposals) с официального сайта языка программирования Python. Он автоматически создаёт два файла формата csv: первый - со списком всех известных на текущий момент статей PEP (с указанием их номеров, названия и текущего статуса), второй - со сводными данными о количестве статей PEP по всем обнаруженным статусам и итоговым числом всех статей. Проект выполнен в рамках финального задания 19-го спринта курса "Python-разработчик плюс" образовательной платформы **Яндекс.Практикум**.

## Технологии

- python
- scrapy

## Установка

Клонируйте репозиторий на ваш компьютер, в локальном репозитории создайте и активируйте виртуальное окружение, обновите менеджер пакетов pip и установите зависимости из файла requirements.txt.

```bash
git clone <адрес репозитория>
python -m venv venv
python -m pip install --upgrade pip
pip install -r requirements.txt
```

## Использование

Находясь в корневой директории приложения, запустите парсер при помощи следующей команды:

```bash
scrapy crawl pep
```
В результате работы парсера в корневой директории приложения в папке results (она будет создана автоматически, если её нет) появятся два описаных выше файла:
- pep_<дата_создания>T<время_содания>.csv
- status_summary_<дата_создания>_<время_содания>.csv

## Авторство

Code - Дима Смолов\
Code review - Стас Лосев

## Лицензия

[MIT](https://choosealicense.com/licenses/mit/)
